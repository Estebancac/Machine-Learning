import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler

# Configurar matplotlib para espa√±ol
plt.rcParams['font.size'] = 11
plt.rcParams['axes.titlesize'] = 12
plt.rcParams['axes.labelsize'] = 11

print("=== AN√ÅLISIS DE REGRESI√ìN LINEAL - DATASET IRIS ===")
print("Creado por: An√°lisis de Datos en Espa√±ol\n")

# 1. Cargar el dataset Iris
iris = load_iris()
df = pd.DataFrame(iris.data, columns=['Longitud S√©palo', 'Ancho S√©palo', 
                                      'Longitud P√©talo', 'Ancho P√©talo'])

print("üìä Informaci√≥n del Dataset:")
print(f"Tama√±o: {df.shape[0]} muestras, {df.shape[1]} variables")
print("\nPrimeras 5 filas:")
print(df.head())

# 2. MODELO SIMPLE: Longitud S√©palo ‚Üí Longitud P√©talo
print("\n" + "="*50)
print("üîµ MODELO DE REGRESI√ìN LINEAL SIMPLE")
print("="*50)

X_simple = df[['Longitud S√©palo']].values
y_simple = df['Longitud P√©talo'].values

correlacion = np.corrcoef(X_simple.flatten(), y_simple)[0,1]
print(f"Variable independiente: Longitud del S√©palo")
print(f"Variable dependiente: Longitud del P√©talo")
print(f"Correlaci√≥n: {correlacion:.3f} (relaci√≥n muy fuerte)")

# Dividir datos
X_train_simple, X_test_simple, y_train_simple, y_test_simple = train_test_split(
    X_simple, y_simple, test_size=0.3, random_state=42)

# Entrenar modelo simple
modelo_simple = LinearRegression()
modelo_simple.fit(X_train_simple, y_train_simple)
y_pred_simple = modelo_simple.predict(X_test_simple)

# M√©tricas modelo simple
r2_simple = r2_score(y_test_simple, y_pred_simple)
mse_simple = mean_squared_error(y_test_simple, y_pred_simple)

print(f"\nüìà Resultados:")
print(f"Ecuaci√≥n: Longitud P√©talo = {modelo_simple.coef_[0]:.3f} √ó Longitud S√©palo + {modelo_simple.intercept_:.3f}")
print(f"R¬≤ = {r2_simple:.3f} (explica {r2_simple*100:.1f}% de la variabilidad)")
print(f"Error cuadr√°tico medio = {mse_simple:.3f}")

# 3. MODELO M√öLTIPLE: Todas las variables ‚Üí Longitud P√©talo
print("\n" + "="*50)
print("üü† MODELO DE REGRESI√ìN LINEAL M√öLTIPLE") 
print("="*50)

X_multiple = df[['Longitud S√©palo', 'Ancho S√©palo', 'Ancho P√©talo']].values
y_multiple = df['Longitud P√©talo'].values

print("Variables independientes: Longitud S√©palo + Ancho S√©palo + Ancho P√©talo")
print("Variable dependiente: Longitud P√©talo")

# Estandarizar variables (importante para regresi√≥n m√∫ltiple)
scaler = StandardScaler()
X_multiple_scaled = scaler.fit_transform(X_multiple)

# Dividir datos
X_train_mult, X_test_mult, y_train_mult, y_test_mult = train_test_split(
    X_multiple_scaled, y_multiple, test_size=0.3, random_state=42)

# Entrenar modelo m√∫ltiple
modelo_multiple = LinearRegression()
modelo_multiple.fit(X_train_mult, y_train_mult)
y_pred_mult = modelo_multiple.predict(X_test_mult)

# M√©tricas modelo m√∫ltiple
r2_multiple = r2_score(y_test_mult, y_pred_mult)
mse_multiple = mean_squared_error(y_test_mult, y_pred_mult)

print(f"\nüìà Resultados:")
print(f"R¬≤ = {r2_multiple:.3f} (explica {r2_multiple*100:.1f}% de la variabilidad)")
print(f"Error cuadr√°tico medio = {mse_multiple:.3f}")

# Importancia de variables
variables = ['Longitud S√©palo', 'Ancho S√©palo', 'Ancho P√©talo']
coeficientes = modelo_multiple.coef_
importancia = list(zip(variables, abs(coeficientes)))
importancia.sort(key=lambda x: x[1], reverse=True)

print(f"\nüéØ Importancia de las variables:")
for i, (var, imp) in enumerate(importancia, 1):
    print(f"{i}. {var}: {imp:.3f}")

# ===============================================
# VISUALIZACIONES EN ESPA√ëOL
# ===============================================

# GR√ÅFICA 1: Regresi√≥n Lineal Simple
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
# Datos de entrenamiento y prueba
plt.scatter(X_train_simple, y_train_simple, alpha=0.7, color='lightblue', 
           s=60, label='Datos Entrenamiento', edgecolors='blue')
plt.scatter(X_test_simple, y_test_simple, alpha=0.7, color='lightcoral', 
           s=60, label='Datos Prueba', edgecolors='red')

# L√≠nea de regresi√≥n
x_rango = np.linspace(X_simple.min(), X_simple.max(), 100).reshape(-1, 1)
y_linea = modelo_simple.predict(x_rango)
plt.plot(x_rango, y_linea, 'green', linewidth=3, 
         label=f'L√≠nea de Regresi√≥n\nR¬≤ = {r2_simple:.3f}')

plt.xlabel('Longitud del S√©palo (cm)')
plt.ylabel('Longitud del P√©talo (cm)')
plt.title('Regresi√≥n Lineal Simple\nLongitud S√©palo vs Longitud P√©talo')
plt.legend()
plt.grid(True, alpha=0.3)

# An√°lisis de residuos
plt.subplot(1, 2, 2)
residuos = y_test_simple - y_pred_simple
plt.scatter(y_pred_simple, residuos, alpha=0.7, color='purple', s=60, edgecolors='darkviolet')
plt.axhline(y=0, color='red', linestyle='--', linewidth=2)
plt.xlabel('Valores Predichos')
plt.ylabel('Residuos (Error)')
plt.title('An√°lisis de Residuos\nModelo Simple')
plt.grid(True, alpha=0.3)

plt.suptitle('üîµ REGRESI√ìN LINEAL SIMPLE', fontsize=14, y=1.02)
plt.tight_layout()
plt.show()

# GR√ÅFICA 2: Regresi√≥n Lineal M√∫ltiple
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
# Valores reales vs predichos
plt.scatter(y_test_mult, y_pred_mult, alpha=0.7, color='orange', s=70, edgecolors='darkorange')
# L√≠nea de predicci√≥n perfecta
min_val = min(y_test_mult.min(), y_pred_mult.min())
max_val = max(y_test_mult.max(), y_pred_mult.max())
plt.plot([min_val, max_val], [min_val, max_val], 'red', linewidth=2, label='Predicci√≥n Perfecta')
plt.xlabel('Valores Reales')
plt.ylabel('Valores Predichos')
plt.title(f'Modelo M√∫ltiple\nR¬≤ = {r2_multiple:.3f}')
plt.legend()
plt.grid(True, alpha=0.3)

# Importancia de variables
plt.subplot(1, 2, 2)
vars_cortas = ['Long. S√©palo', 'Ancho S√©palo', 'Ancho P√©talo']
importancias = [imp for _, imp in importancia]
colores = ['skyblue', 'lightcoral', 'lightgreen']

barras = plt.bar(vars_cortas, importancias, color=colores, alpha=0.8, edgecolor='black')
plt.ylabel('Importancia (|Coeficiente|)')
plt.title('Importancia de Variables\nModelo M√∫ltiple')
plt.xticks(rotation=45, ha='right')
plt.grid(True, alpha=0.3, axis='y')

# A√±adir valores en las barras
for barra, imp in zip(barras, importancias):
    plt.text(barra.get_x() + barra.get_width()/2, barra.get_height() + 0.05,
            f'{imp:.3f}', ha='center', va='bottom', fontweight='bold')

plt.suptitle('üü† REGRESI√ìN LINEAL M√öLTIPLE', fontsize=14, y=1.02)
plt.tight_layout()
plt.show()

# GR√ÅFICA 3: Comparaci√≥n de Modelos (S√©palo vs P√©talo)
plt.figure(figsize=(14, 6))

# Subplot 1: Comparaci√≥n de R¬≤
plt.subplot(1, 3, 1)
modelos = ['Modelo\nSimple', 'Modelo\nM√∫ltiple']
r2_valores = [r2_simple, r2_multiple]
colores_comp = ['lightblue', 'orange']

barras_r2 = plt.bar(modelos, r2_valores, color=colores_comp, alpha=0.8, edgecolor='black')
plt.ylabel('R¬≤ Score')
plt.title('Comparaci√≥n de Modelos\nR¬≤ (Mayor = Mejor)')
plt.ylim(0, 1)
plt.grid(True, alpha=0.3, axis='y')

# Valores en las barras
for barra, valor in zip(barras_r2, r2_valores):
    plt.text(barra.get_x() + barra.get_width()/2, barra.get_height() + 0.02,
            f'{valor:.3f}', ha='center', va='bottom', fontweight='bold', fontsize=11)

# Subplot 2: Regresi√≥n S√©palo vs P√©talo (vista completa)
plt.subplot(1, 3, 2)
plt.scatter(df['Longitud S√©palo'], df['Longitud P√©talo'], 
           alpha=0.7, color='steelblue', s=50, edgecolors='navy')
plt.plot(x_rango, y_linea, 'red', linewidth=3, label=f'Regresi√≥n (r = {correlacion:.3f})')
plt.xlabel('Longitud S√©palo (cm)')
plt.ylabel('Longitud P√©talo (cm)')
plt.title('Relaci√≥n S√©palo vs P√©talo\n(Todos los datos)')
plt.legend()
plt.grid(True, alpha=0.3)

# Subplot 3: Comparaci√≥n de errores
plt.subplot(1, 3, 3)
errores = [mse_simple, mse_multiple]
barras_error = plt.bar(modelos, errores, color=colores_comp, alpha=0.8, edgecolor='black')
plt.ylabel('Error Cuadr√°tico Medio')
plt.title('Comparaci√≥n de Errores\n(Menor = Mejor)')
plt.grid(True, alpha=0.3, axis='y')

# Valores en las barras
for barra, error in zip(barras_error, errores):
    plt.text(barra.get_x() + barra.get_width()/2, barra.get_height() + 0.01,
            f'{error:.3f}', ha='center', va='bottom', fontweight='bold', fontsize=11)

plt.suptitle('üìä COMPARACI√ìN: S√âPALO vs P√âTALO', fontsize=14, y=1.02)
plt.tight_layout()
plt.show()

# ===============================================
# RESUMEN FINAL EN ESPA√ëOL
# ===============================================
print("\n" + "="*60)
print("üéØ RESUMEN FINAL")
print("="*60)

mejora_r2 = r2_multiple - r2_simple
reduccion_error = mse_simple - mse_multiple
porcentaje_mejora = (mejora_r2 / r2_simple * 100)

print(f"\nüìä COMPARACI√ìN DE RESULTADOS:")
print(f"‚Ä¢ Modelo Simple (1 variable):    R¬≤ = {r2_simple:.3f} | Error = {mse_simple:.3f}")
print(f"‚Ä¢ Modelo M√∫ltiple (3 variables): R¬≤ = {r2_multiple:.3f} | Error = {mse_multiple:.3f}")

print(f"\nüöÄ MEJORAS DEL MODELO M√öLTIPLE:")
print(f"‚Ä¢ Incremento en R¬≤: +{mejora_r2:.3f} puntos")
print(f"‚Ä¢ Reducci√≥n en error: -{reduccion_error:.3f}")
print(f"‚Ä¢ Mejora relativa: {porcentaje_mejora:.1f}% mejor que el modelo simple")

print(f"\nüí° CONCLUSIONES:")
print(f"‚Ä¢ La variable m√°s importante es: {importancia[0][0]}")
print(f"‚Ä¢ El modelo m√∫ltiple explica {r2_multiple*100:.1f}% de la variabilidad")
print(f"‚Ä¢ Usar m√∫ltiples variables S√ç mejora significativamente la predicci√≥n")
print(f"‚Ä¢ La correlaci√≥n S√©palo-P√©talo es muy fuerte (r = {correlacion:.3f})")

print("\n" + "="*60)